\section{Results analysis}\label{sec:resultAn}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Comparison between the Linear and Nonlinear Systems}
As it has been mentioned before, the linearization of the Rössler system (\ref{eq:state}) was performed based on previous results in \cite{JS_PL}; there, it was found that the Rössler system is completely stable for large inputs, around $1000V$. Therefore, the equilibrium points were calculated based on this input and the linear model was obtained.

The linearity curve, discussed in section \ref{sec:linearityCurve} and presented in Fig. \ref{fig:linearityCurve}, was developed in order to see where the linear system can successfully reach the same stationary state as the nonlinear. From the linearity curve, the linearity interval can also be extracted: in the curve, it can be observed that both systems (in stationary state) are really close from one another for $u$ between $0V$ to $250V$. This means that the systems have the almost the same stationary state for inputs $u\in[0V,250V]$, and this can also be verified in the simulations performed.

In section \ref{sec:compar_LinearNonlinear}, the inputs were chosen according to the linearity curve. Recall Fig. \ref{fig:comparDelta0}, note that both systems do not present changes in the output and they completely overlap; this is caused by the input selected: $1000V$. Since both systems are exactly at the operation point, which was chosen as an equilibrium point, their states do not change over time. In the next simulation, $1050V$ was selected as input; Fig. \ref{fig:comparDelta50} shows the responses to this input, note that they present almost the exact same behavior, only differing in the peaks and valleys of the oscillation only by a really small factor. This can be partially explained with the linearity curve: both systems are equal in stationary state. The linearity curve does not provide information about the transitory state but as the input selected was chosen near to the operation point, both systems present equal behavior in transitory state as well.

In Fig. \ref{fig:comparDelta200}, the responses are shown for an input of $1200V$. Note that they start to differ a little bit, but it is still a value inside the range of linearity, that is why the stationary state is close. It is important to highlight that the transitory state of the linear approximation is not too different from the nonlinear one, they present similar behavior and same oscillation frequency; it can be observed that the Rössler system present larger damping, as it stabilizes faster than the linear approximation. Finally, in Fig. \ref{fig:comparDelta750}, the responses of the systems are displayed, but for an input outside of the linearity range ($1750V$). As expected, the systems stabilize in different values, but the linear system does a good approximation at the start of the simulation, but couldn't reproduce the strange and quick stabilization of the nonlinear system. The last graph (Fig. \ref{fig:sinInput_compar}) shows the output for both systems to a sine input; since the linear system can successfully represent the nonlinear Rössler, for inputs close to the operation point, it was expected that the output for the nonlinear system would be a sine wave as well and, as this figure shows, the output was exactly the same. This is due to the sine wave chosen: as the amplitude is so small compared with the linearity range, all the values that the sine input take are contained in the linearity interval.

For a comparison in regarding the initial conditions, section \ref{sec:initCondCompar}, the initial conditions for the output state $x_3$ were changed. For a really small change $\varepsilon=0.1V$ and a medium change $\varepsilon=50V$, the system is stable and its state returns to the equilibrium point; this yields that the operation point chosen is an stable equilibrium point (at least in $x_3$) since the nonlinear system, for small changes in the initial conditions, it returns over time to the same equilibrium point, as it is shown in Figs. \ref{fig:ci_x3_01} and \ref{fig:ci_x3_50}, even though their transitory state differ. The next simulation was performed with $\varepsilon=400V$, which is significantly far from the operation point; in Fig. \ref{fig:ci_x3_400}, the responses were presented; notice that the nonlinear system starts to diverge from the operation point; the reason for this is explained by the nonlinear dynamics associated with the Rössler system: it is likely that the system is going to another equilibrium point or just growing unboundedly, or it will start to show strange attractor properties and chaos.

One last comparison was developed with small and medium changes in the initial conditions and the input. From Fig. \ref{fig:Delta_all_small}, the response of both systems in shown; as the input selected ($1003V$) is so close to the operation point (and in the linearity range) and as the changes in the initial conditions are so subtle (stable operation point), both systems will show exactly the same behavior. On the other hand, as it can be observed in Fig. \ref{fig:Delta_all_large}, the nonlinear system shows a strange transitory state that clearly cannot be obtained with the linear approximation; although, both systems stabilize in the same equilibrium point.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Continuous and Discrete Transfer function}
In section \ref{sec:tf}, the continuous transfer function was found. This function has some important properties to notice; in first place, it represents a non-minimum phase system as the zeros, found in \ref{sec:order_reduction}, have a positive real part. This is really noticeable in Fig. \ref{fig:growth_Time} where when the system is reaching its maximum value, instead of growing constantly to the peak it decreases for a moment and then proceeds to keep growing. On the other hand, it is confirmed that the system is stable as all the poles have negative real part.

For the sample time selection, it was specially important that the discretization does not lose main properties of the system; specially, the non-minimum phase property discussed before. As seen in Fig. \ref{fig:tfsStep}, from the discrete system the original signal could be reconstructed without losing too much information about it. Note that even if the sample time selection was selected using a different simulation, for Fig. \ref{fig:tfsImpulse}, the sample time is also a sufficient value to be able to reconstruct the signal without losing too much information. 

It is important to analyze why is there an existence of a lower bound for the sample time, if a big selection could generate problems, such as aliasing. This is explained as, if it was chosen to be indefinitely small, it would be impossible to keep sampling the output in an experiment, as a really low sampling time cannot be replicated easily; also, the discrete signal would almost be continuous therefore, losing its purpose of making the signal discrete.

Additionally, about the response found in Fig. \ref{fig:tfsStep} and Fig. \ref{fig:tfsImpulse}, it is important to notice how, in the first one, it stabilized in other place different from the initial conditions as the input was a constant step that made the system increase it's energy. On the other hand, when the impulse was given to the system in the second figure, it gain a high momentum for a bit and then comes back to the initial point, as the input goes to zero as soon as it transfers that momentum to the system.

Lastly, the discrete ponderation sequence is verified as every point calculated using it overlaps the continuous graph. It was noticed that this weighting sequence is really useful, as the convolution product is an easy operation to calculate and inverse zeta transform would be only used one time instead of using it every time it is needed to simulate with a different input.

In conclusion, the transfer function is a useful tool for simulating and saving the information about a linear system with null initial conditions specially for a SISO system.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Order reduction}
In first place, it is seen that the \textit{Matlab} reduction and the elimination of an insignificant pole are barely different as seen in equation \ref{eq:reduced_matlab} and \ref{eq:reduced_insignificant}. This happens because the software used utilizes numerical algorithms to find a fitting reduction for the system; instead, the other one was using analytical methods which would have more precision. In this manner, it is assured that both models are the same. Furthermore, if Fig. \ref{fig:reduced_matlab} and Fig. \ref{fig:reduced_insignificant} are compared this thesis is confirmed even more, as the minor differences between the two plots can be explained by the same numerical errors.

In second place, there is an apparent contradiction that occurs in Fig. \ref{fig:reduced_insignificant}. It occurs, apparently, that the initial conditions of the system simulated are not 0, as it is seen in the comparison between the reduced system and the original system. This happens due to the obtained transfer function is strictly proper therefore, by the initial value theorem, the output would have a not null initial condition. Although this is a good reason why this occurs it is still an incomplete view of the problem.

In third place, the approximated approach did exactly what the system was purposed of as both systems have the same growth time, stationary state and maximum peak. On the other hand, the approximated approach does not take into account the non-minimum property as that system has not finite zeros; therefore, in the graph it grows continuously instead of taking a slight step backwards as in the original system. This behaviour, although not very representative of the original system, it is desirable as it would represent a causal system; in this manner, this reduced system is preferable than the others if the circuit is going to be recreated experimentally.

In conclusion, there was found two different models (the \textit{Matlab} reduction and analytic one are considered the same as explained before) that represent the system to a certain degree of lower order than the original linear Rössler system.. The analytic system, ensures to represent the system in it's transitory state and final state except at the start in which it changes the initial conditions; the approximated approach was close to the system in it's final state and peak but not during it's transitory state but, it is more practical to use in real life as this reduced system is minimum phase.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Stability Analysis}
The parameter $R_a$, chosen to make the stability analysis has no special properties; the same procedure could have been made for parameter $R_c$ or $RC$. As presented in section \ref{sec:order_reduction}, all the poles of the linearized Rössler system satisfy $\Re(\lambda_i)<0$, therefore the system is stable; from the simulations performed in \ref{sec:compar_LinearNonlinear}, it can also be proved, graphically, that the system is stable.

It was desired to analyze for which values of $R_a$, the linear system is stable; in order to achieve this, it was required to obtain the characteristic polynomial in terms of $R_a$, since the roots of this polynomial are the poles of the linear system. This polynomial, presented in equation (\ref{eq:charPoly}), will have all their roots in the left half-plane when the Routh-Hurwitz necessary and sufficient conditions are satisfied. This process lead to the condition $R_a>184.7341k\Omega$; this implies that the resistor $R_a$ can take values greater than this condition and the linear system will be stable. This is presented as well with the simulations performed, showed in Fig. \ref{fig:Ra_Dentro}a); as expected, the linear system is stable. On the other hand, for the stability of the nonlinear system, it would be necessary to make a deeper analysis, with Lyapunov theory for example; although, the simulations performed and showed in \ref{fig:Ra_Dentro}b) proves that the nonlinear system is stable for $184k\Omega\leq R_a\leq300k\Omega$. It could be also proposed that the Rössler system 

In Fig. \ref{fig:Ra_Fuera}a), the results of the linear system for values of $R_a$ outside the stability region found are presented, this is another validation of the region found. Another important annotation is that the nonlinear system still has stable values outside the region of stability for the linear model, again, since the nonlinear system requires much further study; notice in Fig. \ref{fig:Ra_Fuera}b) that the nonlinear system is still stable for $R_a\geq170k\Omega$. Hence, it can be asserted that the Rössler system in study is stable for $170k\Omega\leq R_a\leq300k\Omega$, which is an important property that had to be mentioned.

All the previous analysis could have been performed with the root locus method, recall Fig. \ref{fig:root_locus}, remember that the root locus starts in the poles and ends in the zeros of the associated transfer function for the parameter in study, as depicted in \ref{sec:root_locus}. The poles are marked with an $\times$ and the zeros with a $\circ$. Note that one root make almost no movement for $k\geq0$ but is in the left half-plane; one of the other two roots starts in the left half-plane as well, whereas the other one start in the right half-plane in $+\infty$, but this plot also shows that there exists some values of $R_a$ that stabilize the system; note that, after the roots reach the break point, both of them start moving towards the left half-plane and actually crossing into it towards the ``end'' of their trajectories, making all of the characteristic polynomial roots satisfy $\Re(\lambda_i)<0$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Bode Diagram}
Firstly, yet again it is confirmed that the linear system is non-minimum phase. This happens because, if it would, then the change of phase of the bode diagram would be -180° instead of -360° as seen in Fig. \ref{fig:contBode}. It is commonly said that for non-minimum phase systems the bode diagram is not a good tool for representing the original system as it gives wrong information; in this manner, it is said in the literature, that the Nyquist diagram is more useful. On the other hand, in our testing the bode diagram gave correct information about the original system.

Furthermore, in Fig. \ref{fig:bodePoints}, it can be seen that for an sine wave input with a frequency of $\omega = 1 rad/s$ the system would have decibels magnitude of -55.5. Using the formulas explained in methods, the stationary state would be given by the wave in equation \ref{eq:sine_ss}. So, the system was simulated with this conditions and as seen in Fig. \ref{fig:bode_sineOutput}, the stationary state matches almost perfectly with the sine wave predicted by the bode diagram. In this manner, the small discrepancies between both simulations can be due to small numerical errors made by the software.

In second place, the discrete bode diagram does have the expected behaviour as it is very similar to the continuous one until it starts approach the Nyquist frequency which, start distorting the original signal so it starts not giving reliable information. Although there was not any simulation performed using this information, it is argued that because the similar behaviour of the discrete bode diagram to the continuous one it is confirmed that it does represent the original system at least for frequencies much smaller than the Nyquist one.

In third place, for the reduced model it is important to notice that the valley encountered at $\omega = 1 rad/s$ has the same magnitude as the one encountered in the original system. Therefore, for frequencies in that valley and before the reduced system is a very good approximation of the original system. On the other hand, for frequencies beyond this valley it would seem as the magnitude becomes constant again not representing at all the behaviour of the not reduced model. This happens because, when the model was reduced the transfer function became not strictly proper therefore, making it have a rate of change of 0; at the same time, this warns that if the reduced model is going to be used instead of the original system, for frequencies larger than $\omega = 2 rad/s$ the reduced model is useless to examine the original system.

In third place, for the closed-loop stability in the bode diagram it is seen that the phase plot does not cross the -180° value therefore it would seem as it did not had any crossover phase frequency. But, \textit{Matlab} presented a value for this property because, there are several distinct definitions to calculate the different margins of the system and instead of seeing when the phase plot crosses the value selected it could be analyzed, instead, for 180°. In this manner, this value for the $k_max$ was verified ins Fig. \ref{fig:response_gains_k} and Fig. \ref{fig:response_gains_unstable} in which inside and outside the stability region it behaves as it is predicted. 

On the other hand, for the unstable plot it would seem the first two values are critically stable instead of unstable; this happens because the growth of the value of the system is changing slightly, therefore it would be needed a lot more time to show this and it would be difficult to present the results in an organized way. Lastly, in Fig. \ref{fig:response_delays}, it was shown that for any delay chosen the system can not be unstabilized by this value.

In conclusion, the bode diagram was a useful tool which presented good information of the system when the input is a sine wave. This information allowed to calculate an interval for the stability of the closed loop system which was confirmed for the simulations presented.