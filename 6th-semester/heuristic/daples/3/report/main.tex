\documentclass[10pt,twoside]{article}
\usepackage[utf8]{inputenc}
\usepackage{natbib}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{adjustbox}
\usepackage[table,xcdraw]{xcolor}
\usepackage{amsmath}
\usepackage[]{todonotes}
\usepackage{fancyhdr}
\usepackage{multirow}
\usepackage{multicol}
\usepackage{xfrac}
% Idioma
\usepackage[english]{babel}

\usepackage[none]{hyphenat}

\usepackage[Alg.]{algorithm}
\usepackage{algpseudocode}

\newcommand{\ignore}[1]{}


\title{Local Search for Heterogeneous Cumulative Capacitated Vehicle Routing Problem}
\author{\emph{David Plazas Escudero}\\
\vspace{0.3cm}
\small{\tt{dplazas@eafit.edu.co}}\\
Departamento de Ciencias Matemáticas\\
Escuela de Ciencias\\
Universidad EAFIT\\
Medellín -- Colombia}
\date{}

\usepackage{anysize}
\marginsize{3cm}{2cm}{2cm}{3cm}

% Configurar encabezado y pie de página
\pagestyle{fancy}
\lfoot[\date{\today}]{\date{\today}}
\rfoot[\thepage]{\thepage}
\cfoot[]{}
\rhead[Plazas (2019)]{Random Search for Heterogeneous Cumulative Capacitated Vehicle Routing Problem}
\lhead[]{}

\fancypagestyle{firststyle}
{
   \fancyhf{}
   \fancyfoot[R]{Last updated: October 15, 2019}
}

\sloppy



\begin{document}

\maketitle

\thispagestyle{firststyle}

% \begin{abstract}
% Buenas
% \vspace{0.2cm}\\
% %
% \noindent \textbf{Keywords:}
% Heuristic, constructive algorithm, vehicle routing problem, heterogeneous-fleet.
% \end{abstract}

\section{Algorithm Description}\label{sec_intro}
\subsection{GRASP}
The GRASP construction is based in the constructive algorithm presented in \cite{constr}, which is an adaptation of the well-known ``sweep'' algorithm from \cite{gillett1974heuristic}. The GRASP implemented in this work is based on the general description provided in ``Handbook of Metaheuristics \cite[Ch. 8]{glover2006handbook}. The pseudo-code for the GRASP is

\begin{algorithm}[H]
  \caption{GRASP} \label{cod:grasp}
  \begin{algorithmic}[1]
    \Procedure{GRASP}{$M$}
        \State nodes, vehicles $\gets$ get\_data()
        \For{$k=1,\ldots,M$}
        \State solution $\gets$ random\_construction(nodes, vehicles)
        \State solution $\gets$ local\_search(solution)
        \State update\_solution(solution, best\_solution)
        \EndFor
    \EndProcedure.
  \end{algorithmic}
\end{algorithm}


The randomization in the construction phase was included in two different parts:
\begin{enumerate}
    \item The algorithm starts selects randomly if it will sweep clockwise or counter-clockwise.
    \item The algorithm originally started always from the node with maximum demand. Now it adds a random noise to the original demands, then looks for the maximum demand and finally continues the process normally. The noise was set to be the uniform random variable \begin{equation}\label{eq:unif}
        \zeta\sim U(-\alpha,\alpha),
    \end{equation}
    where $\alpha:=\dfrac{\max_iq_i + \min_i q_i}{2}$ and $q_i$ is the demand of the $i$-th node.
\end{enumerate}

With the process described above, the GRASP generates 20 feasible solutions, then selects one randomly and continues to the local search phase. This process is repeated $M=3$ times. The local search phase is executed with the VND algorithm described in \cite{ls}, which uses the in-route 2-opt, inter-route 1-1 exchange and in-route best-insertion operators.

\subsection{Noise-Based Local Search}
The noise method applied follows the ideas described in \cite{charon2001noising}. We define a random variable just as the one of Equation \ref{eq:unif}, but $\alpha:=\max_i\max_j d(i,j)/4$ instead, and applied it to each distance in the distance matrix, as
\[
    d_{\mathrm{noised}}(i,j)=d(i,j)+\zeta.
\]
The distances $d(i,j)$ are calculated with the standard Euclidean norm. This distance matrix is then used in the 2-opt method of the VND scheme described in \cite{ls}; the algorithm makes 3 iterations of the 2-opt operator and then updates $\alpha$ by a factor of 0.5. This process is repeated until $\alpha$ is less than $10^{-4}$.

The pseudo-code for 2-opt with noise is
\begin{algorithm}[H]
  \caption{2-opt with Noise} \label{cod:noise}
  \begin{algorithmic}[1]
    \Procedure{two\_opt\_noise}{sol, nodes}
        \State dist\_matrix $\gets$ fill\_dist\_matrix(nodes, 0)
        \State $\alpha\gets \max$(dist\_matrix)/4
        \State dist\_matrix\_noise $\gets$ fill\_dist\_matrix(nodes, $\alpha$)
        \While{$\alpha>10^{-4}$}
        \State j = 0
        \While{$j<3$}
            \State sol $\gets$ two\_opt(sol, dist\_matrix\_noise)
        \EndWhile
        \State $\alpha\gets\alpha*0.5$
        \State dist\_matrix\_noise $\gets$ fill\_dist\_matrix(nodes, $\alpha$)
        \EndWhile
    \EndProcedure.
  \end{algorithmic}
\end{algorithm}
This is just one step in the VND; refer to \cite{ls} for the description of the VND scheme.
\section{Results}
\subsection{GRASP}
The results obtained with GRASP are presented in Table \ref{tab:grasp}. The columns represent (from left to right) the dataset, the number of nodes in the dataset, the \textbf{\%} which is calculated with 
\begin{equation}\label{eq:perc}
    \%=\dfrac{\text{z\_const - z\_grasp}}{\text{z\_const}}\times100\%,
\end{equation}
where \textbf{z\_const} is the objective function value of the initial solution, i.e. constructive algorithm, and \textbf{z\_grasp} is the objective function of the best solution found with GRASP. Finally, the column \textbf{E.T. (s)} stands for the execution time (in seconds) of the algorithm itself (not including the data input/output). Remark: the randomization with GRASP in the constructive phase of the algorithm has to continually check for feasibility, hence the dataset 17 is not included since the problem is unfeasible (for last works, the solution left nodes unassigned); lastly, dataset 20 did not halt, due to unknown reasons to the author, thus not included either.
\begin{table}[ht]
\centering
\begin{tabular}{cccccc}
\hline
\textbf{Instance} & \textbf{Nodes} & \textbf{\%} & \textbf{E.T. (s)} & \textbf{z\_grasp} & \textbf{z\_const} \\ \hline
1                 & 51             & 46.58       & 1.23              & 52132.74          & 97596.7           \\
2                 & 51             & 43.81       & 1.51              & 10343.99          & 18409.89          \\
3                 & 51             & 34.22       & 2.19              & 12063.15          & 18338.96          \\
4                 & 76             & 48.22       & 3.63              & 64552.57          & 124655.47         \\
5                 & 76             & 51.23       & 1.85              & 11106.45          & 22771.86          \\
6                 & 76             & 49.28       & 3.13              & 12718.02          & 25074.22          \\
7                 & 101            & 59.36       & 12.47             & 91289.04          & 224646.61         \\
8                 & 101            & 57.31       & 9.55              & 20442.17          & 47888.63          \\
9                 & 101            & 54.05       & 15.79             & 23480.99          & 51096.46          \\
10                & 151            & 59.33       & 29.87             & 131932.16         & 324414.27         \\
11                & 151            & 60.54       & 25.58             & 29031.85          & 73577.11          \\
12                & 151            & 51.08       & 27.78             & 31201.42          & 63785.01          \\
13                & 200            & 63.74       & 28.91             & 237612.47         & 655387.58         \\
14                & 200            & 52.48       & 24.62             & 175366.04         & 369043.37         \\
15                & 200            & 51.47       & 32.34             & 30570.19          & 62990.86          \\
16                & 121            & 65.75       & 27.38             & 188360.8          & 549961.39         \\
18                & 121            & 63.9        & 20.14             & 28652.63          & 79373.31          \\
19                & 101            & 40.98       & 16.61             & 108653.33         & 184103.51         \\
21                & 101            & 44.55       & 14.53             & 16778.04          & 30260             \\ \hline
\end{tabular}
\caption{Results with GRASP.}
\label{tab:grasp}
\end{table}

\subsection{VND with Noise}
The results for the VND with noise are presented in Table \ref{tab:vnd_noise}. This table follows the conventions mentioned for GRASP including the calculation of the percentage in Equation \ref{eq:perc}, but using \_vnd\_noise naming. Note that the VND algorithm here included datasets 17 and 20. In 17, the algorithm work properly but leaves nodes unassigned; and for dataset 20, the algorithm halted normally.
\begin{table}[H]
\centering
\begin{tabular}{cccccc}
\hline
\textbf{Instance} & \textbf{Nodes} & \textbf{\%} & \textbf{E.T. (s)} & \textbf{z\_vnd\_noise} & \textbf{z\_const} \\ \hline
1                 & 51             & 21.18       & 0.83              & 76922.4                & 97596.7           \\
2                 & 51             & 25.16       & 0.83              & 13778.13               & 18409.89          \\
3                 & 51             & 16.08       & 1.06              & 15390.14               & 18338.96          \\
4                 & 76             & 37.59       & 1.95              & 77794.45               & 124655.47         \\
5                 & 76             & 20.13       & 1.3               & 18187.11               & 22771.86          \\
6                 & 76             & 44.22       & 2.26              & 13986.01               & 25074.22          \\
7                 & 101            & 34.24       & 5.65              & 147726.39              & 224646.61         \\
8                 & 101            & 30.34       & 4.79              & 33358.79               & 47888.63          \\
9                 & 101            & 36.44       & 6.6               & 32476.23               & 51096.46          \\
10                & 151            & 38.68       & 17.31             & 198920.86              & 324414.27         \\
11                & 151            & 23.82       & 15.11             & 56048.59               & 73577.11          \\
12                & 151            & 34.59       & 22.44             & 41722.76               & 63785.01          \\
13                & 200            & 32.08       & 16.59             & 445109.47              & 655387.58         \\
14                & 200            & 25.74       & 23.72             & 274050.72              & 369043.37         \\
15                & 200            & 31.45       & 19.39             & 43181.89               & 62990.86          \\
16                & 121            & 43.43       & 21.6              & 311086.05              & 549961.39         \\
17                & 121            & 3.87        & 3.85              & 74815.49               & 77827.19          \\
18                & 121            & 10.21       & 6.24              & 71265.45               & 79373.31          \\
19                & 101            & 32.16       & 8.37              & 124898.82              & 184103.51         \\
20                & 101            & 10.22       & 6.98              & 24705.81               & 27517.96          \\
21                & 101            & 9.41        & 6.95              & 27413.2                & 30260             \\ \hline
\end{tabular}
\caption{Results for VND with noise.}
\label{tab:vnd_noise}
\end{table}

\section{Conclusion}
The presented algorithms for random search are both good procedures to improve the initial (constructive) solution, as presented in Tables \ref{tab:grasp} and \ref{tab:vnd_noise}, with ``improvement'' percentages relatively high in average; it can be observed that the GRASP implementation gives better solutions in general and the VND in some cases does not make a significant improvement to the initial solution, with low percentages like 3.87\% or 9.41\% in datasets 17 and 21 respectively.

On the other hand, we present one last comparison with the VND results obtained in \cite{ls}, and they are presented in Table \ref{tab:compar}. The \textbf{z\_vnd} are the results obtained with the best local search algorithm from last work, and the last two columns are the percentage deviation from the VND. This percentages represent how far away the noise and GRASP solutions are from the VND; a negative sign indicates that the VND was better. Therefore, observe that the VND with noise is quite bad, since it could get better solutions than the deterministic VND. On the other hand, however, the GRASP implementation gave a much better set of solutions, with low deviations (in general) and in most cases they deviation is positive, which implies that GRASP obtained even better solutions than the VND. For example, in dataset 11, the obtained solution is 22.27\% better than the VND and 60.54\% better than the initial constructive algorithm, which is remarkable.

\begin{table}[H]
\centering
\begin{tabular}{ccccc}
\hline
\textbf{Instance} & \textbf{Nodes} & \textbf{z\_vnd} & \textbf{\%\_noise} & \textbf{\%\_grasp} \\ \hline
1                 & 51             & 48614.5         & -58.23             & -7.24              \\
2                 & 51             & 9926.39         & -38.80             & -4.21              \\
3                 & 51             & 9525.74         & -61.56             & -26.64             \\
4                 & 76             & 70245.22        & -10.75             & 8.10               \\
5                 & 76             & 13933.61        & -30.53             & 20.29              \\
6                 & 76             & 11948.32        & -17.05             & -6.44              \\
7                 & 101            & 113735.48       & -29.89             & 19.74              \\
8                 & 101            & 21854.16        & -52.64             & 6.46               \\
9                 & 101            & 22008.76        & -47.56             & -6.69              \\
10                & 151            & 145624.36       & -36.60             & 9.40               \\
11                & 151            & 37348.96        & -50.07             & 22.27              \\
12                & 151            & 32249.91        & -29.37             & 3.25               \\
13                & 200            & 270287.85       & -64.68             & 12.09              \\
14                & 200            & 160596.62       & -70.65             & -9.20              \\
15                & 200            & 28047.23        & -53.96             & -9.00              \\
16                & 121            & 168556.45       & -84.56             & -11.75             \\
17                & 121            & 31348.27        & -138.66            & -                  \\
18                & 121            & 30196.6         & -136.00            & 5.11               \\
19                & 101            & 111269.86       & -12.25             & 2.35               \\
20                & 101            & 16662.11        & -48.28             & -                  \\
21                & 101            & 18226.72        & -50.40             & 7.95               \\ \hline
\end{tabular}
\caption{Comparison with best local search.}
\label{tab:compar}
\end{table}

It is important to highlight that these solutions, given their random nature, can vary quite easily. The author suggest further experimentation and running the algorithms multiple times to obtain some statistical analysis, such as descriptive data and maybe even confidence intervals. Finally, it is critical to strive for much more effective implementations, and review the unfeasible and non-halting datasets.


{\small
\bibliographystyle{authordate1}

\bibliography{bibs}}


\end{document}
